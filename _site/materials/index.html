<!DOCTYPE html>
<html>

  <head>
  




  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title> Materials - DA323 Multimodal Data Processing and Learning 2.0 / Jan-May 2025 </title>
  <meta name="description" content="Materials - DA323 Multimodal Data Processing and Learning 2.0 / Jan-May 2025">
  
  <link rel="stylesheet" href="/da323W25/_css/main.css">
  <link rel="canonical" href="http://localhost:4000/da323W25/materials/">
  <link rel="alternate" type="application/rss+xml" title="DA323 Multimodal Data Processing and Learning 2.0 / Jan-May 2025 - MFSDSAI, IITG" href="http://localhost:4000/da323W25/feed.xml" />
<link rel='stylesheet' id='open-sans-css'  href='//fonts.googleapis.com/css?family=Open+Sans%3A300italic%2C400italic%2C600italic%2C300%2C400%2C600&#038;subset=latin%2Clatin-ext&#038;ver=4.2.4' type='text/css' media='all' />
<link href='https://fonts.googleapis.com/css?family=Titillium+Web:600italic,600,400,400italic' rel='stylesheet' type='text/css'>




<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.2.0/css/all.css" integrity="sha384-hWVjflwFxL6sNzntih27bfxkr27PmbbK/iSvJ+a4+0owXq79v+lsFkW54bOGbiDQ" crossorigin="anonymous">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper" style="z-index: 100;">
      <table><tr>
          <td><img width="75" src="/da323W25/_images/logo.png" valign="middle"></td>
          <td style="padding-left:10px;"><a class="schoolname" style="font-size: 15px;" class="site-title" href="https://www.iitg.ac.in/dsai/">MFSDSAI, IITG</a>
          <br/>
          <span style="margin-top: -2px;margin-bottom: -10px;" class="site-title"><a href="/da323W25/" title="DA323 Multimodal Data Processing and Learning 2.0 / Jan-May 2025 - MFSDSAI, IITG"><b>DA323 Multimodal Data Processing and Learning 2.0</a></b></span>
          <br/>
          <span class="coursesemeter" style="font-size: 12px;font-weight: bold;margin-top: 10px;display: block;">Jan-May 2025</span>
          </td>
        </tr></table>

    <nav class="site-nav">

      <a href="#" class="menu-icon menu.open">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>  

    <div class="trigger"><h1>Main Navigation</h1>

 <ul class="menu">
    
    <li>
        <a class="page-link" href="/da323W25/">
            <i class="fa fa-home fa-lg"></i> Home
        </a>
    </li>
    
    <li>
        <a class="page-link" href="/da323W25/lectures/">
            <i class="fas fa-book-reader"></i> Lectures
        </a>
    </li>
    
    <li>
        <a class="page-link" href="/da323W25/assignments/">
            <i class="fas fa-user-graduate"></i> Assignments
        </a>
    </li>
    
    <li>
        <a class="page-link" href="/da323W25/project/">
            <i class="fas fa-user-graduate"></i> Project
        </a>
    </li>
    
    <li>
        <a class="page-link" href="/da323W25/materials/">
            <i class="fas fa-book"></i> Materials
        </a>
    </li>
    
    <li>
        <a class="page-link" href="/da323W25/datasets/">
            <i class="fas fa-book"></i> Datasets
        </a>
    </li>
    
</ul>

     </div>  
    </nav>

  </div>

  <div class="header-texture" style="height:100%; z-index: 0; position: absolute; top:0; right: 0; left: 0; 
  background-image: url('/da323W25/_images/pattern.png');" />

</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">Materials</h1>
  </header>

  <article class="post-content">
    <!--- <dl id="" class="wp-caption alignright" style="max-width: 175px">

<dt><a href=""><img class="" src="/da323W25/_images/cover2.jpg" alt="" /></a></dt>

<dd></dd>
</dl>
 -->

<h2 id="why-multimodal">Why Multimodal?</h2>
<ul>
  <li><a href="https://www.sciencedirect.com/science/article/pii/S0167865513002584"><em>Multimodal interaction: A review</em>, M. Turk</a></li>
  <li><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=7214350"><em>Multimodal Data Fusion: An overview of methods, challenges, and prospects</em>, Lahat et al.</a></li>
</ul>

<h2 id="uniomodal-representation-learning">Uniomodal Representation Learning</h2>
<ul>
  <li><a href="https://arxiv.org/pdf/1301.3781"><em>Efficient Estimation of Word Representations in Vector Space</em>, Mikolov et al.</a></li>
  <li><a href="https://jalammar.github.io/illustrated-word2vec/"><em>The Illustrated Word2vec</em>, Jay Alammar</a></li>
  <li><a href="https://www.youtube.com/watch?v=4-QoMdSqG_I"><em>Intuition and Use-cases of embeddings in NLP and beyond</em>, Jay Alammar</a></li>
  <li><a href="https://arxiv.org/pdf/1409.1556"><em>Very Deep Convolutional Networks for Large-Scale Image Recognition (VGGNet)</em>, Karen Simonyan, Andrew Zisserman</a></li>
  <li><a href="https://arxiv.org/pdf/1609.09430"><em>CNN architectures for large-scale audio classification</em>, Hershey et al.</a></li>
  <li></li>
</ul>

<h2 id="self-supervised-representation-learning">Self-supervised Representation Learning</h2>
<ul>
  <li><a href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Mathilde_Caron_Deep_Clustering_for_ECCV_2018_paper.pdf"><em>Deep Clustering for Unsupervised Learning of Visual Features</em>, Caron et al.</a></li>
  <li><a href="https://arxiv.org/abs/2002.05709"><em>A Simple Framework for Contrastive Learning of Visual Representations (SimCLR)</em>, Chen et al.</a></li>
  <li><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=10559458"><em>A Survey on Self-Supervised Learning: Algorithms, Applications, and Future Trends</em>, Gui et al.</a></li>
  <li><a href="https://proceedings.neurips.cc/paper_files/paper/2020/file/92d1e1eb1cd6f9fba3227870bb6d7f07-Paper.pdf"><em>wav2vec2.0: A framework for self-supervised learning of speech representations</em>, Baevski et al.</a></li>
</ul>

<h1 id="machine-learning">Machine Learning</h1>
<ul>
  <li><a href="https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf"><em>Pattern Recognition and Machine Learning</em>, C. Bishop</a></li>
  <li><a href="https://arxiv.org/abs/1310.4546"><em>Distributed Representations of Words and Phrases and their Compositionality</em>, T. Mikolov, I. Sutskever, K. Chen, G. Corrado, J. Dean</a></li>
  <li><a href="https://www.nowpublishers.com/article/Download/MAL-056"><em>An Introduction to Variational Autoencoders</em>, D. P. Kingma, M. Welling</a></li>
</ul>

<h2 id="multimodal-learning">Multimodal Learning</h2>
<ul>
  <li><a href="https://openaccess.thecvf.com/content_ICCV_2017/papers/Arandjelovic_Look_Listen_and_ICCV_2017_paper.pdf"><em>Look, Listen and Learn</em>, R. Arandjelović, A. Zisserman</a></li>
  <li><a href="https://www.justinsalamon.com/uploads/4/3/9/4/4394963/cramer_looklistenlearnmore_icassp_2019.pdf"><em>Look, Listen and Learn More: Design choices for deep audio embeddings</em>, J. Cramer, H. Wu, J. Salamon, J. P. Bello</a></li>
  <li><a href="https://arxiv.org/abs/2103.00020"><em>Learning Transferable Visual Models From Natural Language Supervision (CLIP)</em>, Alec Radford et al.</a></li>
  <li><a href="https://arxiv.org/abs/2306.02596"><em>Learning Audio-Language Representations (CLAP)</em>, Andonian et al.</a></li>
  <li><a href="https://arxiv.org/abs/1902.05766"><em>Speech2Face: Learning the Face Behind a Voice</em>, T. Wen et al.</a></li>
  <li><a href="https://arxiv.org/abs/2103.01913"><em>WIT: Wikipedia-based Image Text Dataset for Multimodal Multilingual Machine Learning</em>, Krishna Srinivasan et al.</a></li>
</ul>

<h2 id="speech-and-audio">Speech and Audio</h2>
<ul>
  <li><a href="https://arxiv.org/abs/1707.04668"><em>Deep Clustering and Conventional Networks for Music Separation: Strong Together</em>, J. R. Hershey et al.</a></li>
</ul>

<h2 id="multimodal-learning-newer-domains">Multimodal Learning: Newer domains</h2>
<ul>
  <li><a href="https://www.nature.com/articles/s41591-022-01981-2"><em>Multimodal Biomedical AI</em>, Julián N. Acosta, Guido J. Falcone, Pranav Rajpurkar, Eric J. Topol</a></li>
  <li><a href="https://neurips.cc/media/neurips-2024/Slides/97824_NAvnRCG.pdf"><em>BIOSCAN-5M: A Multimodal Dataset for Insect Biodiversity</em>, Zahra Gharaee, Scott C. Lowe, ZeMing Gong, Pablo Millan Arias, Nicholas Pellegrino, Austin T. Wang, Joakim Bruslund Haurum, Iuliia Zarubiieva, Lila Kari, Dirk Steinke, Graham W. Taylor, Paul Fieguth, Angel X. Chang</a></li>
</ul>

<h2 id="datasets">Datasets</h2>
<ul>
  <li>[MINST]</li>
  <li>[FMINST]</li>
  <li>[CIFAR]</li>
  <li>[CANDOR]</li>
  <li>[Coswara]</li>
  <li>[ImageNet]</li>
  <li>[WIT]</li>
  <li>[Google Audio Dataset]</li>
  <li>[Vox celeb dataset]</li>
</ul>

  </article>

</div>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

<!--     <h2 class="footer-heading">MFSDSAI, IITG</h2> -->
         <div class="footer-col-wrapper">
      <div class="footer-col  footer-col-1">
 

         <p class="text">
Mehta Family School of Data Science and Artificial Intelligence<br />
IIT Guwahati, India<br />

      </div>

      <div class="footer-col  footer-col-2">
       <ul class="social-media-list">
     

          

          

          

          

          
  <li>
    <a href="https://www.iitg.ac.in/dsai/">
      <i class="fas fa-globe" style="color:gray"></i> iitg.ac.in/dsai/
    </a>
  </li>




       
        </ul>
      </div>
    </div>

  </div>

</footer>

  </body>

</html>
<!-- d.s.m.s.050600.062508.030515.080516.030818 | "Baby, I'm Yours" -->