I"s<!--- <dl id="" class="wp-caption alignright" style="max-width: 175px">

<dt><a href=""><img class="" src="/da323W25/_images/cover2.jpg" alt="" /></a></dt>

<dd></dd>
</dl>
 -->

<h2 id="why-multimodal">Why Multimodal?</h2>
<ul>
  <li><a href="https://www.sciencedirect.com/science/article/pii/S0167865513002584"><em>Multimodal interaction: A review</em>, M. Turk</a></li>
  <li><a href="https://arxiv.org/abs/1310.4546"><em>Distributed Representations of Words and Phrases and their Compositionality</em>, T. Mikolov, I. Sutskever, K. Chen, G. Corrado, J. Dean</a></li>
  <li><a href="https://arxiv.org/abs/1312.6114"><em>Auto-Encoding Variational Bayes</em>, D. P. Kingma, M. Welling</a></li>
  <li><em>Brain-Informed Source Separation</em> â€“ <em>(Link not found. Please provide more details such as authors or venue.)</em></li>
</ul>

<h2 id="uniomodal-representation-learning">Uniomodal Representation Learning</h2>
<ul>
  <li>[<em>Efficient Estimation of Word Representations in
Vector Space</em>]</li>
</ul>

<h2 id="machine-learning">Machine Learning</h2>
<ul>
  <li><a href="https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf"><em>Pattern Recognition and Machine Learning</em>, C. Bishop</a></li>
  <li><a href="https://arxiv.org/abs/1310.4546"><em>Distributed Representations of Words and Phrases and their Compositionality</em>, T. Mikolov, I. Sutskever, K. Chen, G. Corrado, J. Dean</a></li>
  <li><a href="https://arxiv.org/abs/1312.6114"><em>Auto-Encoding Variational Bayes</em>, D. P. Kingma, M. Welling</a></li>
  <li><em>Brain-Informed Source Separation</em> â€“ <em>(Link not found. Please provide more details such as authors or venue.)</em></li>
</ul>

<h2 id="multimodal-learning">Multimodal Learning</h2>
<ul>
  <li><a href="https://openaccess.thecvf.com/content_ICCV_2017/papers/Arandjelovic_Look_Listen_and_ICCV_2017_paper.pdf"><em>Look, Listen and Learn</em>, R. ArandjeloviÄ‡, A. Zisserman</a></li>
  <li><a href="https://www.justinsalamon.com/uploads/4/3/9/4/4394963/cramer_looklistenlearnmore_icassp_2019.pdf"><em>Look, Listen and Learn More: Design choices for deep audio embeddings</em>, J. Cramer, H. Wu, J. Salamon, J. P. Bello</a></li>
  <li><a href="https://arxiv.org/abs/2103.00020"><em>Learning Transferable Visual Models From Natural Language Supervision (CLIP)</em>, Alec Radford et al.</a></li>
  <li><a href="https://arxiv.org/abs/2306.02596"><em>Learning Audio-Language Representations (CLAP)</em>, Andonian et al.</a></li>
  <li><a href="https://arxiv.org/abs/1902.05766"><em>Speech2Face: Learning the Face Behind a Voice</em>, T. Wen et al.</a></li>
  <li><a href="https://arxiv.org/abs/2103.01913"><em>WIT: Wikipedia-based Image Text Dataset for Multimodal Multilingual Machine Learning</em>, Krishna Srinivasan et al.</a></li>
</ul>

<h2 id="representation-learning">Representation Learning</h2>
<ul>
  <li><a href="https://arxiv.org/abs/2002.05709"><em>A Simple Framework for Contrastive Learning of Visual Representations (SimCLR)</em>, Chen et al.</a></li>
</ul>

<h2 id="speech-and-audio">Speech and Audio</h2>
<ul>
  <li><a href="https://arxiv.org/abs/1707.04668"><em>Deep Clustering and Conventional Networks for Music Separation: Strong Together</em>, J. R. Hershey et al.</a></li>
</ul>

<h2 id="multimodal-learning-newer-domains">Multimodal Learning: Newer domains</h2>
<ul>
  <li><a href="https://www.nature.com/articles/s41591-022-01981-2"><em>Multimodal Biomedical AI</em>, JuliÃ¡n N. Acosta, Guido J. Falcone, Pranav Rajpurkar, Eric J. Topol</a></li>
  <li><a href="https://neurips.cc/media/neurips-2024/Slides/97824_NAvnRCG.pdf"><em>BIOSCAN-5M: A Multimodal Dataset for Insect Biodiversity</em>, Zahra Gharaee, Scott C. Lowe, ZeMing Gong, Pablo Millan Arias, Nicholas Pellegrino, Austin T. Wang, Joakim Bruslund Haurum, Iuliia Zarubiieva, Lila Kari, Dirk Steinke, Graham W. Taylor, Paul Fieguth, Angel X. Chang</a></li>
</ul>

:ET